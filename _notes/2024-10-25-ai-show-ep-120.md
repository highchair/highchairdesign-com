---
layout: note
title: "Episode 120 — OpenAI Microsoft Drama, AI Jobs Impact, Sequoia’s New GenAI Market Analysis, NotebookLM updates, Adobe Max"
date: 2024-10-25 14:00:00 -0500
source: '<a href="https://podcasts.apple.com/us/podcast/openai-microsoft-drama-major-study-on-ai-job-impact/id1548733275?i=1000673986921">The Artificial Intelligence Show, Episode 120</a>'
media: "Podcast"
categories: [ AI, Leadership ]
---

## OpenAI and Microsoft

Microsoft and OpenAI had an odd relationship. According to their contract, if the board of OpenAI declares they have achieved GenAI (which no one fully agrees on what it is), they can stop sharing their technology with Microsoft. All this is while Microsoft are hiring their own experts to pursue their own AI solutions that are not dependent on OpenAI. They fully admitted they are in competition.

OpenAI negotiated a competing deal with Oracle for a 10 billion computing power agreement. Is Microsoft “slow playing” OpenAI even though they have invested so much money into supporting what OpenAI is doing?

Secrets at OpenAI are flying out the door. 14 co-founders have left for other jobs or to start their own models.

## Brookings Institute Report

Data-driven approach to investigating the impact of AI on different jobs. Their methods sound much like the tool this author, Paul Roetzer, created, JobsGPT. Almost all jobs will have some portions of it that can be replaced by today’s standard AI models. And the exposure level will continue to increase, potentially replacing some jobs entirely.

Massive disruption is coming, but few are talking about it. They don’t seem to realize what is going to happen. If we only get the current models without AGI, it is still technology that can disrupt the workplace. What does another 12 months of this growth look like?

Some large entity needs to take on the study of these impacts. We don’t have much time to figure this out before market forces will completely disrupt work. And if the market is allowed to decide based on profit drivers, the landscape of work is not going to look very good.

## Sequoia’s New GenAI Market Analysis

“Thinking Slow” is a new evolution of model operation. A reasoning layer is being introduced which enables “System 2” thinking instead of pattern-matching. The more inference time a model is given, the more accurate its results of “thinking.”

+ System 1 thinking: fact based, memorization, and retrieval
+ System 2 thinking: requires research, thinking, and formulating an answer that resolves the question

This will have major effects on business. Systems can start to demonstrate superhuman capabilities.

Observers used to think that the market would gather around one “foundation model.” Everyone else would play for the scraps. That does not seem to be how the market will work. Every three months, new models come out and outpace the competition.

### A possible hierarchal model scenario

Instead, what we might see is a hierarchal system. There might be many large, complex models that do the high level, super human reasoning that gets close to Advanced General Intelligence. But these models will be the most expensive to run, and therefore, only suited to the most complex of tasks and “thinking.” But most current tasks that humans are most interested in GenAI doing are simple and repetitive. There is no reason why a future might be the highly intelligent AI telling lower level AIs what to do. They don’t require a dominant, billion-dollar “Frontier” model. Instead, that model becomes the Project Manager for all the other models. Once a prompt is entered, the most complex model assigns the work to the most well-suited model.

### Wrapper software is more useful than we thought

We thought wrappers around other models, like Khan Academy, were not going to continue to be useful. Instead, what they are seeing is that these domain-specific wrappers are very useful because they apply specific expertise suited for a particular industry. General-purpose AI has not been good enough to perform in these scenarios, and the wrappers who are reselling core LLMs are actually valuable because of the domain expertise they bring to the market.

> Sidenote: Use NotebookLM to explain a complex article at a 6th or 7th grade level

## Rapid Fires

+ Google’s NotebookLM has been used by 80k organizations and recently got some updates. No longer experimental and the audio podcast portion has been given need dials and knobs to customize the output — customize focus, expertise level, you can listen while working within NotebookLM
+ NotebookLM business is coming out for group accounts with privacy built-in for source material
+ Adobe seems to be keeping itself very relevant with their new AI tools announced at Max
+ MidJourney will release an updated web tool that will edit existing images and retexture objects within them. Concerns include deep fakes, copyright infringement, and the like
+ Playground is also a player in this space creating memes, social media images, logos, and other small design projects. Understands cultural references and art direction prompts. Positioning themselves as Playground for designers.
+ The founder of HubSpot and creator of Drift creates a company called “Agency” to automate the tasks typically handled by customer service agents. Learns from phone conversations and chat. Can onboard customers as well. Seems to be a company that wants to replace a subset of consulting agencies.
+ UK government wants people to be able to opt-out of AI scraping, but the default is opt-in. The creative industry prefers the opt-in model because it allows more direct compensation.
+ Microsoft is introducing the creation of autonomous agents within CoPilot. Examples include a sales qualification agent and an HR customer service agent.
+ Demis Hassabis from Google DeepMind speaks at the Times Tech summit. His definition of AGI is a general system capable out of the box, capable of doing anything a human can do. No distinction in performance level, though, which means at a 50% of all humans, average level? Or 99% virtuoso level? He thinks there are some blockers to AGI, which are infinite memory, advanced personalization, and computer vision.
  + He is a cautious optimist — not a doomer and not a techno-optimist. He has concerns, and to paraphrase, he said that I’ve seen systems that scale within hours, and that process is what scares me. Anyone who is not concerned about the speed at which these systems can scale themselves isn’t paying attention.
